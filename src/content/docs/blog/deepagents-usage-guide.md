---
title: DeepAgents æ·±åº¦æ™ºèƒ½ä½“ä½¿ç”¨æŒ‡å—
description: æ·±å…¥äº†è§£ LangChain DeepAgents æ¡†æ¶ï¼Œæ„å»ºå…·æœ‰è§„åˆ’ã€è®°å¿†å’Œå­æ™ºèƒ½ä½“èƒ½åŠ›çš„é«˜çº§ AI Agent
pubDate: 2025-11-04
---

## DeepAgents ç®€ä»‹

DeepAgents æ˜¯ LangChain æ¨å‡ºçš„ä¸€ä¸ª Python æ¡†æ¶ï¼Œç”¨äºæ„å»º"æ·±åº¦"AI æ™ºèƒ½ä½“ã€‚ä¼ ç»Ÿçš„ Agent é€šè¿‡ç®€å•çš„å·¥å…·è°ƒç”¨å¾ªç¯æ¥å·¥ä½œï¼Œä½†åœ¨å¤„ç†å¤æ‚ã€å¤šæ­¥éª¤ä»»åŠ¡æ—¶å¾€å¾€è¡¨ç°ä¸ä½³ã€‚DeepAgents é€šè¿‡å¼•å…¥å››ä¸ªæ ¸å¿ƒèƒ½åŠ›æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š

- ğŸ¯ **è§„åˆ’å·¥å…·ï¼ˆPlanning Toolï¼‰**ï¼šå¸®åŠ© Agent åˆ†è§£ä»»åŠ¡å¹¶è·Ÿè¸ªè¿›åº¦
- ğŸ“ **æ–‡ä»¶ç³»ç»Ÿï¼ˆFile Systemï¼‰**ï¼šæä¾›çŸ­æœŸå’Œé•¿æœŸè®°å¿†èƒ½åŠ›
- ğŸ¤– **å­æ™ºèƒ½ä½“ï¼ˆSub Agentsï¼‰**ï¼šæ”¯æŒä»»åŠ¡å§”æ´¾å’Œä¸Šä¸‹æ–‡éš”ç¦»
- ğŸ“ **è¯¦ç»†æç¤ºè¯ï¼ˆDetailed Promptï¼‰**ï¼šä¼˜åŒ–çš„ç³»ç»Ÿæç¤ºè¯æŒ‡å¯¼ Agent è¡Œä¸º

### æ ¸å¿ƒç‰¹æ€§

- âœ¨ **é«˜çº§ä»»åŠ¡è§„åˆ’**ï¼šé€šè¿‡ TodoList ä¸­é—´ä»¶ç®¡ç†å¤æ‚ä»»åŠ¡
- ğŸ’¾ **ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šæ–‡ä»¶ç³»ç»Ÿå·¥å…·é¿å…ä¸Šä¸‹æ–‡çª—å£æº¢å‡º
- ğŸ”„ **æ¨¡å—åŒ–æ¶æ„**ï¼šåŸºäºä¸­é—´ä»¶çš„å¯ç»„åˆè®¾è®¡
- ğŸŒ **å¤šæ¨¡å‹æ”¯æŒ**ï¼šæ”¯æŒ Claudeã€GPT-4 ç­‰ä¸»æµ LLM
- ğŸ”Œ **MCP é›†æˆ**ï¼šæ”¯æŒ Model Context Protocol å·¥å…·

## æ¶æ„è®¾è®¡

### DeepAgents æ ¸å¿ƒæ¶æ„

```mermaid
graph TB
    A[ç”¨æˆ·è¯·æ±‚] --> B[Deep Agent]
    B --> C[Planning Middleware<br/>ä»»åŠ¡è§„åˆ’]
    B --> D[Filesystem Middleware<br/>æ–‡ä»¶ç³»ç»Ÿ]
    B --> E[SubAgent Middleware<br/>å­æ™ºèƒ½ä½“]

    C --> C1[write_todos<br/>ä»»åŠ¡åˆ—è¡¨ç®¡ç†]

    D --> D1[ls - åˆ—å‡ºæ–‡ä»¶]
    D --> D2[read_file - è¯»å–æ–‡ä»¶]
    D --> D3[write_file - å†™å…¥æ–‡ä»¶]
    D --> D4[edit_file - ç¼–è¾‘æ–‡ä»¶]

    E --> E1[task - å§”æ´¾ä»»åŠ¡]
    E --> E2[SubAgent 1]
    E --> E3[SubAgent 2]

    B --> F[è‡ªå®šä¹‰å·¥å…·]
    F --> F1[internet_search]
    F --> F2[database_query]
    F --> F3[...]

    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#ffe1f5
    style D fill:#ffe1f5
    style E fill:#ffe1f5
    style F fill:#e1ffe1
```

### å·¥ä½œæµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant A as Deep Agent
    participant P as Planning
    participant F as Filesystem
    participant S as SubAgent
    participant T as å·¥å…·

    U->>A: æäº¤å¤æ‚ä»»åŠ¡
    A->>P: åˆ›å»ºä»»åŠ¡è®¡åˆ’
    P-->>A: è¿”å› TODO åˆ—è¡¨

    loop æ‰§è¡Œä»»åŠ¡
        A->>T: è°ƒç”¨å·¥å…·è·å–æ•°æ®
        T-->>A: è¿”å›å¤§é‡æ•°æ®
        A->>F: å°†æ•°æ®å†™å…¥æ–‡ä»¶
        F-->>A: ç¡®è®¤ä¿å­˜

        A->>S: å§”æ´¾å­ä»»åŠ¡
        S->>S: ç‹¬ç«‹æ‰§è¡Œ
        S-->>A: è¿”å›ç»“æœ

        A->>P: æ›´æ–°ä»»åŠ¡çŠ¶æ€
    end

    A->>F: è¯»å–æ±‡æ€»æ•°æ®
    A->>U: è¿”å›æœ€ç»ˆç»“æœ
```

## å®‰è£…é…ç½®

### å®‰è£… DeepAgents

```bash
# ä½¿ç”¨ pip
pip install deepagents

# ä½¿ç”¨ uv
uv add deepagents

# ä½¿ç”¨ poetry
poetry add deepagents
```

### ç¯å¢ƒé…ç½®

```bash
# è®¾ç½® API Keys
export ANTHROPIC_API_KEY="your-api-key"
export OPENAI_API_KEY="your-api-key"
export TAVILY_API_KEY="your-tavily-key"  # ç”¨äºç½‘ç»œæœç´¢
```

## å¿«é€Ÿå¼€å§‹

### åŸºç¡€ç¤ºä¾‹ï¼šåˆ›å»ºç ”ç©¶åŠ©æ‰‹

```python
import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

# åˆå§‹åŒ– Tavily å®¢æˆ·ç«¯
tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

# å®šä¹‰ç½‘ç»œæœç´¢å·¥å…·
def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """æ‰§è¡Œç½‘ç»œæœç´¢"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )

# ç³»ç»Ÿæç¤ºè¯
research_instructions = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¿›è¡Œæ·±å…¥ç ”ç©¶ï¼Œç„¶åæ’°å†™ç²¾ç¾çš„æŠ¥å‘Šã€‚

ä½ å¯ä»¥ä½¿ç”¨ internet_search å·¥å…·ä½œä¸ºä¸»è¦çš„ä¿¡æ¯æ”¶é›†æ‰‹æ®µã€‚

## å·¥ä½œæµç¨‹
1. ä½¿ç”¨ write_todos å·¥å…·è§„åˆ’ç ”ç©¶æ­¥éª¤
2. ä½¿ç”¨ internet_search æ”¶é›†ä¿¡æ¯
3. å°†é‡è¦ä¿¡æ¯å†™å…¥æ–‡ä»¶ç³»ç»Ÿ
4. åˆ†ææ•´ç†åæ’°å†™æœ€ç»ˆæŠ¥å‘Š
"""

# åˆ›å»º Deep Agent
agent = create_deep_agent(
    tools=[internet_search],
    system_prompt=research_instructions,
)

# è°ƒç”¨ Agent
result = agent.invoke({
    "messages": [{"role": "user", "content": "ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿ"}]
})

print(result["messages"][-1].content)
```

### æµå¼è¾“å‡ºç¤ºä¾‹

```python
# æµå¼è¾“å‡º Agent çš„æ€è€ƒè¿‡ç¨‹
for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "ç ”ç©¶ DeepAgents çš„æ ¸å¿ƒç‰¹æ€§"}]},
    stream_mode="values"
):
    if "messages" in chunk:
        chunk["messages"][-1].pretty_print()
```

## æ ¸å¿ƒä¸­é—´ä»¶è¯¦è§£

### 1. TodoListMiddleware - ä»»åŠ¡è§„åˆ’

TodoListMiddleware ä¸º Agent æä¾›äº† `write_todos` å·¥å…·ï¼Œç”¨äºç®¡ç†ä»»åŠ¡åˆ—è¡¨ã€‚

```python
from langchain.agents import create_agent
from langchain.agents.middleware import TodoListMiddleware

agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[
        TodoListMiddleware(
            system_prompt="ä½¿ç”¨ write_todos å·¥å…·æ¥è§„åˆ’å’Œè·Ÿè¸ªä»»åŠ¡è¿›åº¦"
        ),
    ],
)
```

**ä½¿ç”¨åœºæ™¯**ï¼š
- å¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡
- éœ€è¦åŠ¨æ€è°ƒæ•´è®¡åˆ’çš„åœºæ™¯
- é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡è·Ÿè¸ª

### 2. FilesystemMiddleware - æ–‡ä»¶ç³»ç»Ÿ

FilesystemMiddleware æä¾›å››ä¸ªæ ¸å¿ƒå·¥å…·ï¼š

```python
from deepagents.middleware.filesystem import FilesystemMiddleware

agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[
        FilesystemMiddleware(
            system_prompt="å°†å¤§é‡æ•°æ®å†™å…¥æ–‡ä»¶ç³»ç»Ÿä»¥èŠ‚çœä¸Šä¸‹æ–‡ç©ºé—´",
            custom_tool_descriptions={
                "ls": "åˆ—å‡ºå½“å‰ç›®å½•çš„æ–‡ä»¶",
                "read_file": "è¯»å–æ–‡ä»¶å†…å®¹ï¼Œå¯æŒ‡å®šè¡Œæ•°èŒƒå›´",
                "write_file": "åˆ›å»ºæ–°æ–‡ä»¶å¹¶å†™å…¥å†…å®¹",
                "edit_file": "ç¼–è¾‘ç°æœ‰æ–‡ä»¶"
            }
        ),
    ],
)
```

**å·¥å…·è¯´æ˜**ï¼š
- `ls`ï¼šåˆ—å‡ºæ–‡ä»¶ç³»ç»Ÿä¸­çš„æ–‡ä»¶
- `read_file`ï¼šè¯»å–æ•´ä¸ªæ–‡ä»¶æˆ–æŒ‡å®šè¡Œæ•°
- `write_file`ï¼šåˆ›å»ºæ–°æ–‡ä»¶
- `edit_file`ï¼šç¼–è¾‘ç°æœ‰æ–‡ä»¶

**ä½¿ç”¨åœºæ™¯**ï¼š
- å¤„ç†å¤§é‡æœç´¢ç»“æœ
- éœ€è¦ä¿å­˜ä¸­é—´ç»“æœ
- æ„å»ºçŸ¥è¯†åº“

### 3. SubAgentMiddleware - å­æ™ºèƒ½ä½“

SubAgentMiddleware å…è®¸ä¸» Agent å§”æ´¾ä»»åŠ¡ç»™ä¸“é—¨çš„å­ Agentã€‚

```python
from langchain_core.tools import tool
from deepagents.middleware.subagents import SubAgentMiddleware

@tool
def get_weather(city: str) -> str:
    """è·å–åŸå¸‚å¤©æ°”"""
    return f"{city} çš„å¤©æ°”æ˜¯æ™´å¤©"

# å®šä¹‰å­æ™ºèƒ½ä½“
weather_subagent = {
    "name": "weather-agent",
    "description": "ä¸“é—¨å¤„ç†å¤©æ°”æŸ¥è¯¢çš„å­æ™ºèƒ½ä½“",
    "system_prompt": "ä½¿ç”¨ get_weather å·¥å…·è·å–å¤©æ°”ä¿¡æ¯",
    "tools": [get_weather],
    "model": "openai:gpt-4o",  # å¯é€‰ï¼šä½¿ç”¨ä¸åŒçš„æ¨¡å‹
}

agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[
        SubAgentMiddleware(
            default_model="anthropic:claude-sonnet-4-20250514",
            default_tools=[],
            subagents=[weather_subagent],
        )
    ],
)
```

**ä¼˜åŠ¿**ï¼š
- ä¸Šä¸‹æ–‡éš”ç¦»ï¼šå­ä»»åŠ¡ä¸æ±¡æŸ“ä¸» Agent ä¸Šä¸‹æ–‡
- ä¸“ä¸šåŒ–ï¼šä¸åŒå­ Agent å¯ä»¥æœ‰ä¸åŒçš„å·¥å…·å’Œæç¤ºè¯
- å¹¶è¡Œå¤„ç†ï¼šå¯ä»¥åŒæ—¶è¿è¡Œå¤šä¸ªå­ä»»åŠ¡

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æ¨¡å‹

```python
from langchain.chat_models import init_chat_model
from deepagents import create_deep_agent

# ä½¿ç”¨ GPT-4
model = init_chat_model("openai:gpt-4o")
agent = create_deep_agent(
    model=model,
    tools=[internet_search],
)

# ä½¿ç”¨ Claude
model = init_chat_model("anthropic:claude-sonnet-4-20250514")
agent = create_deep_agent(
    model=model,
    tools=[internet_search],
)
```

### äººæœºåä½œï¼ˆHuman-in-the-Loopï¼‰

```python
from langchain_core.tools import tool
from deepagents import create_deep_agent

@tool
def delete_file(filename: str) -> str:
    """åˆ é™¤æ–‡ä»¶ï¼ˆéœ€è¦äººå·¥ç¡®è®¤ï¼‰"""
    return f"æ–‡ä»¶ {filename} å·²åˆ é™¤"

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[delete_file],
    interrupt_on={
        "delete_file": {
            "allowed_decisions": ["approve", "edit", "reject"]
        },
    }
)
```

### ä½¿ç”¨é¢„æ„å»ºçš„å­æ™ºèƒ½ä½“

```python
from langgraph import StateGraph

# åˆ›å»ºè‡ªå®šä¹‰ LangGraph å›¾
def create_data_analyzer():
    workflow = StateGraph(...)
    # æ„å»ºè‡ªå®šä¹‰å›¾
    return workflow.compile()

analyzer_graph = create_data_analyzer()

# ä½œä¸ºå­æ™ºèƒ½ä½“ä½¿ç”¨
custom_subagent = {
    "name": "data-analyzer",
    "description": "ä¸“é—¨ç”¨äºå¤æ‚æ•°æ®åˆ†æçš„å­æ™ºèƒ½ä½“",
    "runnable": analyzer_graph
}

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    subagents=[custom_subagent]
)
```

### MCP å·¥å…·é›†æˆ

DeepAgents æ”¯æŒ Model Context Protocol (MCP) å·¥å…·ï¼š

```python
import asyncio
from langchain_mcp_adapters.client import MultiServerMCPClient
from deepagents import create_deep_agent

async def main():
    # æ”¶é›† MCP å·¥å…·
    mcp_client = MultiServerMCPClient(...)
    mcp_tools = await mcp_client.get_tools()

    # åˆ›å»º Agent
    agent = create_deep_agent(
        tools=mcp_tools,
        model="anthropic:claude-sonnet-4-20250514"
    )

    # æµå¼è°ƒç”¨
    async for chunk in agent.astream(
        {"messages": [{"role": "user", "content": "åˆ†ææœ€æ–°çš„æŠ€æœ¯è¶‹åŠ¿"}]},
        stream_mode="values"
    ):
        if "messages" in chunk:
            chunk["messages"][-1].pretty_print()

asyncio.run(main())
```

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹ 1ï¼šæ™ºèƒ½ç ”ç©¶åŠ©æ‰‹

æ„å»ºä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œæ·±åº¦ç ”ç©¶å¹¶ç”ŸæˆæŠ¥å‘Šçš„ Agentï¼š

```python
import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
):
    """ç½‘ç»œæœç´¢å·¥å…·"""
    return tavily_client.search(
        query,
        max_results=max_results,
        topic=topic,
    )

research_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶åˆ†æå¸ˆã€‚

## å·¥ä½œæµç¨‹
1. **è§„åˆ’é˜¶æ®µ**ï¼šä½¿ç”¨ write_todos åˆ›å»ºç ”ç©¶è®¡åˆ’
2. **ä¿¡æ¯æ”¶é›†**ï¼šä½¿ç”¨ internet_search æ”¶é›†ç›¸å…³ä¿¡æ¯
3. **æ•°æ®ç®¡ç†**ï¼šå°†æœç´¢ç»“æœå†™å…¥æ–‡ä»¶ç³»ç»Ÿï¼Œé¿å…ä¸Šä¸‹æ–‡æº¢å‡º
4. **åˆ†ææ•´ç†**ï¼šä»æ–‡ä»¶ä¸­è¯»å–ä¿¡æ¯ï¼Œè¿›è¡Œæ·±åº¦åˆ†æ
5. **æŠ¥å‘Šæ’°å†™**ï¼šç”Ÿæˆç»“æ„åŒ–çš„ç ”ç©¶æŠ¥å‘Š

## æ³¨æ„äº‹é¡¹
- æ¯æ¬¡æœç´¢åå°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶
- ä½¿ç”¨æè¿°æ€§çš„æ–‡ä»¶åï¼ˆå¦‚ï¼šsearch_results_topic.txtï¼‰
- å®šæœŸæ›´æ–° TODO åˆ—è¡¨ä»¥è·Ÿè¸ªè¿›åº¦
- æœ€ç»ˆæŠ¥å‘Šåº”åŒ…å«ï¼šæ‘˜è¦ã€è¯¦ç»†åˆ†æã€ç»“è®ºå’Œå‚è€ƒæ¥æº
"""

research_agent = create_deep_agent(
    tools=[internet_search],
    system_prompt=research_prompt,
    model="anthropic:claude-sonnet-4-20250514"
)

# æ‰§è¡Œç ”ç©¶ä»»åŠ¡
result = research_agent.invoke({
    "messages": [{
        "role": "user",
        "content": "ç ”ç©¶ 2024 å¹´ AI Agent æŠ€æœ¯çš„æœ€æ–°å‘å±•è¶‹åŠ¿ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"
    }]
})

print(result["messages"][-1].content)
```

### æ¡ˆä¾‹ 2ï¼šå¤šé¢†åŸŸä¸“å®¶ç³»ç»Ÿ

ä½¿ç”¨å­æ™ºèƒ½ä½“æ„å»ºå¤šé¢†åŸŸä¸“å®¶ç³»ç»Ÿï¼š

```python
from langchain_core.tools import tool
from deepagents import create_deep_agent

# æŠ€æœ¯å·¥å…·
@tool
def search_technical_docs(query: str) -> str:
    """æœç´¢æŠ€æœ¯æ–‡æ¡£"""
    # å®ç°æŠ€æœ¯æ–‡æ¡£æœç´¢
    return f"æŠ€æœ¯æ–‡æ¡£æœç´¢ç»“æœï¼š{query}"

@tool
def analyze_code(code: str) -> str:
    """åˆ†æä»£ç è´¨é‡"""
    # å®ç°ä»£ç åˆ†æ
    return f"ä»£ç åˆ†æç»“æœ"

# å¸‚åœºå·¥å…·
@tool
def get_market_data(product: str) -> str:
    """è·å–å¸‚åœºæ•°æ®"""
    # å®ç°å¸‚åœºæ•°æ®è·å–
    return f"{product} çš„å¸‚åœºæ•°æ®"

@tool
def competitor_analysis(company: str) -> str:
    """ç«äº‰å¯¹æ‰‹åˆ†æ"""
    # å®ç°ç«äº‰åˆ†æ
    return f"{company} çš„ç«äº‰åˆ†æ"

# å®šä¹‰å­æ™ºèƒ½ä½“
tech_expert = {
    "name": "tech-expert",
    "description": "æŠ€æœ¯ä¸“å®¶ï¼Œè´Ÿè´£æŠ€æœ¯è¯„ä¼°å’Œä»£ç å®¡æŸ¥",
    "system_prompt": "ä½ æ˜¯æŠ€æœ¯ä¸“å®¶ï¼Œæ“…é•¿ä»£ç å®¡æŸ¥å’ŒæŠ€æœ¯æ¶æ„åˆ†æ",
    "tools": [search_technical_docs, analyze_code],
}

market_expert = {
    "name": "market-expert",
    "description": "å¸‚åœºä¸“å®¶ï¼Œè´Ÿè´£å¸‚åœºè°ƒç ”å’Œç«äº‰åˆ†æ",
    "system_prompt": "ä½ æ˜¯å¸‚åœºåˆ†æä¸“å®¶ï¼Œæ“…é•¿å¸‚åœºè¶‹åŠ¿å’Œç«äº‰åˆ†æ",
    "tools": [get_market_data, competitor_analysis],
}

# åˆ›å»ºä¸» Agent
supervisor_agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    system_prompt="""ä½ æ˜¯é¡¹ç›®æ€»ç›‘ï¼Œè´Ÿè´£åè°ƒæŠ€æœ¯å’Œå¸‚åœºå›¢é˜Ÿã€‚

å½“æ”¶åˆ°ä»»åŠ¡æ—¶ï¼š
1. åˆ†æä»»åŠ¡éœ€æ±‚
2. å°†æŠ€æœ¯ç›¸å…³ä»»åŠ¡å§”æ´¾ç»™ tech-expert
3. å°†å¸‚åœºç›¸å…³ä»»åŠ¡å§”æ´¾ç»™ market-expert
4. æ•´åˆä¸¤ä¸ªå›¢é˜Ÿçš„ç»“æœ
5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
""",
    subagents=[tech_expert, market_expert]
)

# æ‰§è¡Œä»»åŠ¡
result = supervisor_agent.invoke({
    "messages": [{
        "role": "user",
        "content": "è¯„ä¼°å¼€å‘ä¸€ä¸ª AI é©±åŠ¨çš„å®¢æˆ·æœåŠ¡å¹³å°çš„å¯è¡Œæ€§"
    }]
})
```

### æ¡ˆä¾‹ 3ï¼šæ–‡æ¡£å¤„ç†åŠ©æ‰‹

å¤„ç†å¤§é‡æ–‡æ¡£å¹¶æå–å…³é”®ä¿¡æ¯ï¼š

```python
from langchain_core.tools import tool
from deepagents import create_deep_agent
import os

@tool
def read_pdf(filepath: str) -> str:
    """è¯»å– PDF æ–‡ä»¶å†…å®¹"""
    # å®ç° PDF è¯»å–é€»è¾‘
    return f"PDF å†…å®¹ï¼š{filepath}"

@tool
def extract_tables(filepath: str) -> str:
    """ä»æ–‡æ¡£ä¸­æå–è¡¨æ ¼"""
    # å®ç°è¡¨æ ¼æå–
    return "æå–çš„è¡¨æ ¼æ•°æ®"

@tool
def summarize_section(text: str, section: str) -> str:
    """æ€»ç»“æ–‡æ¡£ç‰¹å®šç« èŠ‚"""
    # å®ç°ç« èŠ‚æ€»ç»“
    return f"{section} çš„æ€»ç»“"

doc_processor_prompt = """ä½ æ˜¯æ–‡æ¡£å¤„ç†ä¸“å®¶ã€‚

## å¤„ç†æµç¨‹
1. ä½¿ç”¨ read_pdf è¯»å–æ–‡æ¡£
2. å°†æ–‡æ¡£å†…å®¹å†™å…¥æ–‡ä»¶ç³»ç»Ÿï¼ˆæŒ‰ç« èŠ‚åˆ†å‰²ï¼‰
3. ä½¿ç”¨ extract_tables æå–è¡¨æ ¼æ•°æ®
4. å¯¹æ¯ä¸ªç« èŠ‚ä½¿ç”¨ summarize_section ç”Ÿæˆæ‘˜è¦
5. å°†æ‰€æœ‰æ‘˜è¦æ•´åˆæˆæœ€ç»ˆæŠ¥å‘Š

## æ–‡ä»¶ç»„ç»‡
- raw_content/ï¼šåŸå§‹æ–‡æ¡£å†…å®¹
- sections/ï¼šæŒ‰ç« èŠ‚åˆ†å‰²çš„å†…å®¹
- tables/ï¼šæå–çš„è¡¨æ ¼
- summaries/ï¼šå„ç« èŠ‚æ‘˜è¦
- final_report.mdï¼šæœ€ç»ˆæŠ¥å‘Š
"""

doc_agent = create_deep_agent(
    tools=[read_pdf, extract_tables, summarize_section],
    system_prompt=doc_processor_prompt,
    model="anthropic:claude-sonnet-4-20250514"
)

# å¤„ç†æ–‡æ¡£
result = doc_agent.invoke({
    "messages": [{
        "role": "user",
        "content": "å¤„ç† annual_report_2024.pdf å¹¶ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"
    }]
})
```

## æœ€ä½³å®è·µ

### 1. æç¤ºè¯å·¥ç¨‹

```python
# âœ… å¥½çš„æç¤ºè¯
good_prompt = """ä½ æ˜¯ä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚

## å·¥ä½œæµç¨‹
1. ä½¿ç”¨ write_todos è§„åˆ’åˆ†ææ­¥éª¤
2. æ”¶é›†æ•°æ®å¹¶ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ
3. é€æ­¥åˆ†ææ•°æ®
4. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š

## æ–‡ä»¶ç®¡ç†
- data/ï¼šåŸå§‹æ•°æ®
- analysis/ï¼šåˆ†æç»“æœ
- reports/ï¼šæœ€ç»ˆæŠ¥å‘Š

## è¾“å‡ºæ ¼å¼
ä½¿ç”¨ Markdown æ ¼å¼ï¼ŒåŒ…å«ï¼š
- æ‰§è¡Œæ‘˜è¦
- è¯¦ç»†åˆ†æ
- å¯è§†åŒ–å›¾è¡¨
- ç»“è®ºå’Œå»ºè®®
"""

# âŒ ä¸å¥½çš„æç¤ºè¯
bad_prompt = "ä½ æ˜¯æ•°æ®åˆ†æå¸ˆï¼Œå¸®æˆ‘åˆ†ææ•°æ®"
```

### 2. å·¥å…·è®¾è®¡åŸåˆ™

```python
from langchain_core.tools import tool

# âœ… å¥½çš„å·¥å…·è®¾è®¡
@tool
def search_database(
    query: str,
    table: str,
    limit: int = 10,
    filters: dict = None
) -> str:
    """
    æœç´¢æ•°æ®åº“

    Args:
        query: SQL æŸ¥è¯¢è¯­å¥
        table: è¡¨å
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
        filters: é¢å¤–çš„è¿‡æ»¤æ¡ä»¶

    Returns:
        æŸ¥è¯¢ç»“æœçš„ JSON å­—ç¬¦ä¸²
    """
    # å®ç°é€»è¾‘
    pass

# âŒ ä¸å¥½çš„å·¥å…·è®¾è®¡
@tool
def search(q: str) -> str:
    """æœç´¢"""  # æè¿°ä¸æ¸…æ™°
    pass
```

### 3. é”™è¯¯å¤„ç†

```python
from deepagents import create_deep_agent
import logging

logging.basicConfig(level=logging.INFO)

try:
    agent = create_deep_agent(
        tools=[internet_search],
        system_prompt=research_prompt,
    )

    result = agent.invoke({
        "messages": [{"role": "user", "content": "ç ”ç©¶ä¸»é¢˜"}]
    })

except Exception as e:
    logging.error(f"Agent æ‰§è¡Œå¤±è´¥: {e}")
    # å®ç°é‡è¯•é€»è¾‘æˆ–é™çº§æ–¹æ¡ˆ
```

### 4. æ€§èƒ½ä¼˜åŒ–

```python
# ä½¿ç”¨æ£€æŸ¥ç‚¹å®ç°çŠ¶æ€æŒä¹…åŒ–
from langgraph.checkpoint.memory import MemorySaver

checkpointer = MemorySaver()

agent = create_deep_agent(
    tools=[internet_search],
    system_prompt=research_prompt,
    checkpointer=checkpointer  # å¯ç”¨æ£€æŸ¥ç‚¹
)

# ä½¿ç”¨çº¿ç¨‹ ID æ¢å¤ä¼šè¯
config = {"configurable": {"thread_id": "session-123"}}
result = agent.invoke(
    {"messages": [{"role": "user", "content": "ç»§ç»­ä¹‹å‰çš„ç ”ç©¶"}]},
    config=config
)
```

## ä¸ä¼ ç»Ÿ Agent çš„å¯¹æ¯”

| ç‰¹æ€§ | ä¼ ç»Ÿ Agent | Deep Agent |
|------|-----------|------------|
| ä»»åŠ¡è§„åˆ’ | âŒ æ— å†…ç½®è§„åˆ’ | âœ… TodoList ä¸­é—´ä»¶ |
| ä¸Šä¸‹æ–‡ç®¡ç† | âŒ å®¹æ˜“æº¢å‡º | âœ… æ–‡ä»¶ç³»ç»Ÿå·¥å…· |
| ä»»åŠ¡å§”æ´¾ | âŒ å•ä¸€ Agent | âœ… å­æ™ºèƒ½ä½“æ”¯æŒ |
| å¤æ‚ä»»åŠ¡ | âš ï¸ è¡¨ç°ä¸€èˆ¬ | âœ… ä¸“ä¸ºå¤æ‚ä»»åŠ¡è®¾è®¡ |
| å¯æ‰©å±•æ€§ | âš ï¸ æœ‰é™ | âœ… ä¸­é—´ä»¶æ¶æ„ |
| å­¦ä¹ æ›²çº¿ | âœ… ç®€å• | âš ï¸ éœ€è¦ç†è§£ä¸­é—´ä»¶ |

## å¸¸è§é—®é¢˜

### Q1: DeepAgents é€‚åˆä»€ä¹ˆåœºæ™¯ï¼Ÿ

**é€‚åˆ**ï¼š
- éœ€è¦å¤šæ­¥éª¤è§„åˆ’çš„å¤æ‚ä»»åŠ¡
- å¤„ç†å¤§é‡æ•°æ®çš„åœºæ™¯
- éœ€è¦ä¸“ä¸šåŒ–å­ä»»åŠ¡çš„åº”ç”¨
- é•¿æ—¶é—´è¿è¡Œçš„ç ”ç©¶æˆ–åˆ†æä»»åŠ¡

**ä¸é€‚åˆ**ï¼š
- ç®€å•çš„å•æ¬¡å·¥å…·è°ƒç”¨
- å®æ—¶æ€§è¦æ±‚æé«˜çš„åœºæ™¯
- èµ„æºå—é™çš„ç¯å¢ƒ

### Q2: å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Ÿ

```python
# å¤æ‚æ¨ç†ä»»åŠ¡ï¼šä½¿ç”¨ Claude Sonnet
agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[...]
)

# æˆæœ¬æ•æ„Ÿåœºæ™¯ï¼šä½¿ç”¨ GPT-4o-mini
agent = create_deep_agent(
    model="openai:gpt-4o-mini",
    tools=[...]
)

# ä¸åŒå­ä»»åŠ¡ä½¿ç”¨ä¸åŒæ¨¡å‹
subagent = {
    "name": "simple-task",
    "model": "openai:gpt-4o-mini",  # ç®€å•ä»»åŠ¡ç”¨å°æ¨¡å‹
    "tools": [...]
}
```

### Q3: å¦‚ä½•è°ƒè¯• DeepAgentsï¼Ÿ

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# ä½¿ç”¨æµå¼è¾“å‡ºè§‚å¯Ÿæ€è€ƒè¿‡ç¨‹
for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "ä»»åŠ¡"}]},
    stream_mode="values"
):
    if "messages" in chunk:
        print(chunk["messages"][-1])

# æ£€æŸ¥æ–‡ä»¶ç³»ç»ŸçŠ¶æ€
# Agent ä¼šå°†ä¸­é—´ç»“æœä¿å­˜åˆ°æ–‡ä»¶ï¼Œå¯ä»¥æŸ¥çœ‹è¿™äº›æ–‡ä»¶
```

## æ€»ç»“

DeepAgents é€šè¿‡å¼•å…¥è§„åˆ’ã€æ–‡ä»¶ç³»ç»Ÿå’Œå­æ™ºèƒ½ä½“ç­‰æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº† AI Agent å¤„ç†å¤æ‚ä»»åŠ¡çš„èƒ½åŠ›ã€‚ä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬ï¼š

âœ… **æ›´å¥½çš„ä»»åŠ¡è§„åˆ’**ï¼šé€šè¿‡ TodoList ç®¡ç†å¤æ‚æµç¨‹
âœ… **é«˜æ•ˆçš„ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šæ–‡ä»¶ç³»ç»Ÿé¿å…ä¸Šä¸‹æ–‡æº¢å‡º
âœ… **æ¨¡å—åŒ–è®¾è®¡**ï¼šä¸­é—´ä»¶æ¶æ„æ˜“äºæ‰©å±•
âœ… **ä¸“ä¸šåŒ–å¤„ç†**ï¼šå­æ™ºèƒ½ä½“å®ç°ä»»åŠ¡éš”ç¦»

## å‚è€ƒèµ„æº

- [DeepAgents GitHub](https://github.com/langchain-ai/deepagents)
- [LangChain å®˜æ–¹æ–‡æ¡£](https://docs.langchain.com/)
- [LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [Deep Agents åšå®¢](https://blog.langchain.com/deep-agents/)
- [DataCamp æ•™ç¨‹](https://www.datacamp.com/tutorial/deep-agents)
